{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2o3CBNRLZZ5",
        "outputId": "14611856-9bfb-4793-ec61-061132672d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################   SVC   ################\n",
            "Best parameters set found on development set:\n",
            "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Grid scores on development set:\n",
            "0.961 (+/-0.026) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.967 (+/-0.036) for {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "0.853 (+/-0.013) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.967 (+/-0.036) for {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
            "0.977 (+/-0.035) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.960 (+/-0.062) for {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "0.961 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.960 (+/-0.062) for {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}\n",
            "0.982 (+/-0.034) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.950 (+/-0.048) for {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "0.977 (+/-0.035) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.950 (+/-0.048) for {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}\n",
            "0.975 (+/-0.045) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.942 (+/-0.033) for {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "0.982 (+/-0.028) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.942 (+/-0.033) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'}\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        47\n",
            "           1       0.97      0.97      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[45  2]\n",
            " [ 2 65]]\n",
            "Precision Score: \n",
            "\n",
            "0.9701492537313433\n",
            "################   DecisionTreeClassifier   ################\n",
            "Best parameters set found on development set:\n",
            "{'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Grid scores on development set:\n",
            "0.933 (+/-0.037) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.918 (+/-0.065) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "0.897 (+/-0.066) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 100}\n",
            "0.913 (+/-0.034) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.906 (+/-0.045) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
            "0.897 (+/-0.090) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 100}\n",
            "0.911 (+/-0.071) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.922 (+/-0.030) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "0.903 (+/-0.059) for {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
            "0.934 (+/-0.046) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.932 (+/-0.033) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "0.879 (+/-0.074) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 100}\n",
            "0.924 (+/-0.040) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.922 (+/-0.057) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
            "0.908 (+/-0.049) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 100}\n",
            "0.901 (+/-0.033) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.906 (+/-0.060) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "0.902 (+/-0.028) for {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
            "0.939 (+/-0.049) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.892 (+/-0.070) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "0.890 (+/-0.074) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 100}\n",
            "0.911 (+/-0.029) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.927 (+/-0.033) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
            "0.902 (+/-0.059) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 100}\n",
            "0.928 (+/-0.073) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.911 (+/-0.045) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "0.892 (+/-0.114) for {'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
            "0.914 (+/-0.049) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.916 (+/-0.048) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "0.911 (+/-0.034) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 100}\n",
            "0.908 (+/-0.072) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.925 (+/-0.011) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
            "0.895 (+/-0.053) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 100}\n",
            "0.910 (+/-0.081) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.890 (+/-0.064) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "0.889 (+/-0.078) for {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
            "0.922 (+/-0.031) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.917 (+/-0.052) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "0.856 (+/-0.097) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 100}\n",
            "0.911 (+/-0.077) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.916 (+/-0.043) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
            "0.895 (+/-0.055) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 100}\n",
            "0.879 (+/-0.076) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.929 (+/-0.040) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "0.896 (+/-0.106) for {'max_depth': 1000, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
            "0.910 (+/-0.048) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.909 (+/-0.095) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "0.902 (+/-0.048) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 100}\n",
            "0.916 (+/-0.055) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.926 (+/-0.028) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
            "0.891 (+/-0.017) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 100}\n",
            "0.935 (+/-0.023) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.908 (+/-0.061) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "0.907 (+/-0.066) for {'max_depth': 1000, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
            "0.924 (+/-0.050) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.922 (+/-0.031) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "0.909 (+/-0.041) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 100}\n",
            "0.906 (+/-0.048) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.935 (+/-0.039) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
            "0.887 (+/-0.063) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 100}\n",
            "0.911 (+/-0.045) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.909 (+/-0.051) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "0.898 (+/-0.053) for {'max_depth': 10000, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
            "0.918 (+/-0.050) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.904 (+/-0.009) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "0.878 (+/-0.057) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 100}\n",
            "0.922 (+/-0.034) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.907 (+/-0.060) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
            "0.894 (+/-0.082) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 100}\n",
            "0.884 (+/-0.039) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.903 (+/-0.049) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "0.881 (+/-0.036) for {'max_depth': 10000, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 100}\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95        47\n",
            "           1       0.97      0.96      0.96        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.95      0.96      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[45  2]\n",
            " [ 3 64]]\n",
            "Precision Score: \n",
            "\n",
            "0.9696969696969697\n",
            "################   MLPClassifier   ################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "{'activation': 'tanh', 'alpha': 0.0005, 'hidden_layer_sizes': (10,), 'max_iter': 1000}\n",
            "Grid scores on development set:\n",
            "0.951 (+/-0.059) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (5,), 'max_iter': 200}\n",
            "0.977 (+/-0.028) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (5,), 'max_iter': 1000}\n",
            "0.977 (+/-0.030) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'max_iter': 200}\n",
            "0.977 (+/-0.028) for {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'max_iter': 1000}\n",
            "0.948 (+/-0.050) for {'activation': 'logistic', 'alpha': 0.0005, 'hidden_layer_sizes': (5,), 'max_iter': 200}\n",
            "0.980 (+/-0.027) for {'activation': 'logistic', 'alpha': 0.0005, 'hidden_layer_sizes': (5,), 'max_iter': 1000}\n",
            "0.972 (+/-0.025) for {'activation': 'logistic', 'alpha': 0.0005, 'hidden_layer_sizes': (10,), 'max_iter': 200}\n",
            "0.976 (+/-0.024) for {'activation': 'logistic', 'alpha': 0.0005, 'hidden_layer_sizes': (10,), 'max_iter': 1000}\n",
            "0.965 (+/-0.040) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (5,), 'max_iter': 200}\n",
            "0.979 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (5,), 'max_iter': 1000}\n",
            "0.970 (+/-0.039) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'max_iter': 200}\n",
            "0.973 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'max_iter': 1000}\n",
            "0.970 (+/-0.028) for {'activation': 'tanh', 'alpha': 0.0005, 'hidden_layer_sizes': (5,), 'max_iter': 200}\n",
            "0.979 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.0005, 'hidden_layer_sizes': (5,), 'max_iter': 1000}\n",
            "0.974 (+/-0.034) for {'activation': 'tanh', 'alpha': 0.0005, 'hidden_layer_sizes': (10,), 'max_iter': 200}\n",
            "0.982 (+/-0.028) for {'activation': 'tanh', 'alpha': 0.0005, 'hidden_layer_sizes': (10,), 'max_iter': 1000}\n",
            "0.959 (+/-0.041) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (5,), 'max_iter': 200}\n",
            "0.974 (+/-0.041) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (5,), 'max_iter': 1000}\n",
            "0.959 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'max_iter': 200}\n",
            "0.970 (+/-0.031) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'max_iter': 1000}\n",
            "0.951 (+/-0.044) for {'activation': 'relu', 'alpha': 0.0005, 'hidden_layer_sizes': (5,), 'max_iter': 200}\n",
            "0.979 (+/-0.022) for {'activation': 'relu', 'alpha': 0.0005, 'hidden_layer_sizes': (5,), 'max_iter': 1000}\n",
            "0.970 (+/-0.026) for {'activation': 'relu', 'alpha': 0.0005, 'hidden_layer_sizes': (10,), 'max_iter': 200}\n",
            "0.975 (+/-0.021) for {'activation': 'relu', 'alpha': 0.0005, 'hidden_layer_sizes': (10,), 'max_iter': 1000}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95        47\n",
            "           1       0.97      0.96      0.96        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.95      0.96      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[45  2]\n",
            " [ 3 64]]\n",
            "Precision Score: \n",
            "\n",
            "0.9696969696969697\n",
            "################   GaussianNB   ################\n",
            "Best parameters set found on development set:\n",
            "{}\n",
            "Grid scores on development set:\n",
            "0.948 (+/-0.045) for {}\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88        47\n",
            "           1       0.92      0.91      0.92        67\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.90      0.90      0.90       114\n",
            "weighted avg       0.90      0.90      0.90       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[42  5]\n",
            " [ 6 61]]\n",
            "Precision Score: \n",
            "\n",
            "0.9242424242424242\n",
            "################   LogisticRegression   ################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "60 fits failed out of a total of 120.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.98668945 0.98668945        nan        nan\n",
            " 0.98071876 0.98071876        nan        nan 0.98071876 0.98071876\n",
            "        nan        nan 0.9805704  0.9805704         nan        nan\n",
            " 0.98238366 0.98238366        nan        nan 0.98238366 0.98238366]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "{'fit_intercept': True, 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
            "Grid scores on development set:\n",
            "nan (+/-nan) for {'fit_intercept': True, 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'fit_intercept': True, 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
            "0.987 (+/-0.029) for {'fit_intercept': True, 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
            "0.987 (+/-0.029) for {'fit_intercept': True, 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
            "nan (+/-nan) for {'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
            "0.981 (+/-0.034) for {'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
            "0.981 (+/-0.034) for {'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
            "nan (+/-nan) for {'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
            "0.981 (+/-0.034) for {'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
            "0.981 (+/-0.034) for {'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
            "nan (+/-nan) for {'fit_intercept': False, 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'fit_intercept': False, 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
            "0.981 (+/-0.028) for {'fit_intercept': False, 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
            "0.981 (+/-0.028) for {'fit_intercept': False, 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
            "nan (+/-nan) for {'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
            "0.982 (+/-0.028) for {'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
            "0.982 (+/-0.028) for {'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
            "nan (+/-nan) for {'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
            "0.982 (+/-0.028) for {'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
            "0.982 (+/-0.028) for {'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "60 fits failed out of a total of 120.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.98668945 0.98668945        nan        nan\n",
            " 0.98071876 0.98071876        nan        nan 0.98071876 0.98071876\n",
            "        nan        nan 0.9805704  0.9805704         nan        nan\n",
            " 0.98238366 0.98238366        nan        nan 0.98238366 0.98238366]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        47\n",
            "           1       0.97      0.97      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[45  2]\n",
            " [ 2 65]]\n",
            "Precision Score: \n",
            "\n",
            "0.9701492537313433\n",
            "################   KNeighborsClassifier   ################\n",
            "Best parameters set found on development set:\n",
            "{'algorithm': 'ball_tree', 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
            "Grid scores on development set:\n",
            "0.971 (+/-0.029) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
            "0.971 (+/-0.029) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
            "0.968 (+/-0.017) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
            "0.968 (+/-0.017) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
            "0.963 (+/-0.026) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 3, 'weights': 'uniform'}\n",
            "0.963 (+/-0.026) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 3, 'weights': 'distance'}\n",
            "0.971 (+/-0.031) for {'algorithm': 'ball_tree', 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
            "0.969 (+/-0.029) for {'algorithm': 'ball_tree', 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
            "0.964 (+/-0.057) for {'algorithm': 'ball_tree', 'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}\n",
            "0.967 (+/-0.045) for {'algorithm': 'ball_tree', 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n",
            "0.959 (+/-0.028) for {'algorithm': 'ball_tree', 'n_neighbors': 10, 'p': 3, 'weights': 'uniform'}\n",
            "0.964 (+/-0.035) for {'algorithm': 'ball_tree', 'n_neighbors': 10, 'p': 3, 'weights': 'distance'}\n",
            "0.966 (+/-0.047) for {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1, 'weights': 'uniform'}\n",
            "0.966 (+/-0.047) for {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1, 'weights': 'distance'}\n",
            "0.959 (+/-0.052) for {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 2, 'weights': 'uniform'}\n",
            "0.962 (+/-0.042) for {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 2, 'weights': 'distance'}\n",
            "0.965 (+/-0.033) for {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 3, 'weights': 'uniform'}\n",
            "0.962 (+/-0.027) for {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 3, 'weights': 'distance'}\n",
            "0.971 (+/-0.029) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
            "0.971 (+/-0.029) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
            "0.968 (+/-0.017) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
            "0.968 (+/-0.017) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
            "0.963 (+/-0.026) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 3, 'weights': 'uniform'}\n",
            "0.963 (+/-0.026) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 3, 'weights': 'distance'}\n",
            "0.971 (+/-0.031) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
            "0.969 (+/-0.029) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
            "0.964 (+/-0.057) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}\n",
            "0.967 (+/-0.045) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n",
            "0.959 (+/-0.028) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 3, 'weights': 'uniform'}\n",
            "0.964 (+/-0.035) for {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 3, 'weights': 'distance'}\n",
            "0.966 (+/-0.047) for {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 1, 'weights': 'uniform'}\n",
            "0.966 (+/-0.047) for {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 1, 'weights': 'distance'}\n",
            "0.959 (+/-0.052) for {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 2, 'weights': 'uniform'}\n",
            "0.962 (+/-0.042) for {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 2, 'weights': 'distance'}\n",
            "0.965 (+/-0.033) for {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 3, 'weights': 'uniform'}\n",
            "0.962 (+/-0.027) for {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 3, 'weights': 'distance'}\n",
            "0.971 (+/-0.029) for {'algorithm': 'brute', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
            "0.971 (+/-0.029) for {'algorithm': 'brute', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
            "0.968 (+/-0.017) for {'algorithm': 'brute', 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
            "0.968 (+/-0.017) for {'algorithm': 'brute', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
            "0.963 (+/-0.026) for {'algorithm': 'brute', 'n_neighbors': 5, 'p': 3, 'weights': 'uniform'}\n",
            "0.963 (+/-0.026) for {'algorithm': 'brute', 'n_neighbors': 5, 'p': 3, 'weights': 'distance'}\n",
            "0.971 (+/-0.031) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
            "0.969 (+/-0.029) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
            "0.964 (+/-0.057) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}\n",
            "0.967 (+/-0.045) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n",
            "0.959 (+/-0.028) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 3, 'weights': 'uniform'}\n",
            "0.964 (+/-0.035) for {'algorithm': 'brute', 'n_neighbors': 10, 'p': 3, 'weights': 'distance'}\n",
            "0.966 (+/-0.047) for {'algorithm': 'brute', 'n_neighbors': 20, 'p': 1, 'weights': 'uniform'}\n",
            "0.966 (+/-0.047) for {'algorithm': 'brute', 'n_neighbors': 20, 'p': 1, 'weights': 'distance'}\n",
            "0.959 (+/-0.052) for {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2, 'weights': 'uniform'}\n",
            "0.962 (+/-0.042) for {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2, 'weights': 'distance'}\n",
            "0.965 (+/-0.033) for {'algorithm': 'brute', 'n_neighbors': 20, 'p': 3, 'weights': 'uniform'}\n",
            "0.962 (+/-0.027) for {'algorithm': 'brute', 'n_neighbors': 20, 'p': 3, 'weights': 'distance'}\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        47\n",
            "           1       0.96      0.97      0.96        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[44  3]\n",
            " [ 2 65]]\n",
            "Precision Score: \n",
            "\n",
            "0.9558823529411765\n",
            "################   BaggingClassifier   ################\n",
            "Best parameters set found on development set:\n",
            "{'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'random_state': None}\n",
            "Grid scores on development set:\n",
            "0.943 (+/-0.016) for {'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 10, 'random_state': None}\n",
            "0.945 (+/-0.028) for {'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 20, 'random_state': None}\n",
            "0.957 (+/-0.026) for {'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 100, 'random_state': None}\n",
            "0.944 (+/-0.017) for {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 10, 'random_state': None}\n",
            "0.957 (+/-0.024) for {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 20, 'random_state': None}\n",
            "0.951 (+/-0.026) for {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 100, 'random_state': None}\n",
            "0.940 (+/-0.046) for {'max_features': 1.0, 'max_samples': 0.5, 'n_estimators': 10, 'random_state': None}\n",
            "0.945 (+/-0.050) for {'max_features': 1.0, 'max_samples': 0.5, 'n_estimators': 20, 'random_state': None}\n",
            "0.943 (+/-0.033) for {'max_features': 1.0, 'max_samples': 0.5, 'n_estimators': 100, 'random_state': None}\n",
            "0.935 (+/-0.043) for {'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'random_state': None}\n",
            "0.951 (+/-0.044) for {'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 20, 'random_state': None}\n",
            "0.960 (+/-0.028) for {'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'random_state': None}\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        47\n",
            "           1       0.97      0.97      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[45  2]\n",
            " [ 2 65]]\n",
            "Precision Score: \n",
            "\n",
            "0.9701492537313433\n",
            "################   RandomForestClassifier   ################\n",
            "Best parameters set found on development set:\n",
            "{'criterion': 'entropy', 'max_depth': None, 'max_features': 1.0, 'n_estimators': 20}\n",
            "Grid scores on development set:\n",
            "0.951 (+/-0.051) for {'criterion': 'gini', 'max_depth': None, 'max_features': 0.5, 'n_estimators': 10}\n",
            "0.950 (+/-0.018) for {'criterion': 'gini', 'max_depth': None, 'max_features': 0.5, 'n_estimators': 20}\n",
            "0.947 (+/-0.027) for {'criterion': 'gini', 'max_depth': None, 'max_features': 0.5, 'n_estimators': 100}\n",
            "0.943 (+/-0.027) for {'criterion': 'gini', 'max_depth': None, 'max_features': 1.0, 'n_estimators': 10}\n",
            "0.952 (+/-0.036) for {'criterion': 'gini', 'max_depth': None, 'max_features': 1.0, 'n_estimators': 20}\n",
            "0.959 (+/-0.018) for {'criterion': 'gini', 'max_depth': None, 'max_features': 1.0, 'n_estimators': 100}\n",
            "0.938 (+/-0.060) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 0.5, 'n_estimators': 10}\n",
            "0.958 (+/-0.013) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 0.5, 'n_estimators': 20}\n",
            "0.952 (+/-0.022) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 0.5, 'n_estimators': 100}\n",
            "0.938 (+/-0.036) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 1.0, 'n_estimators': 10}\n",
            "0.940 (+/-0.044) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 1.0, 'n_estimators': 20}\n",
            "0.950 (+/-0.023) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 1.0, 'n_estimators': 100}\n",
            "0.933 (+/-0.039) for {'criterion': 'gini', 'max_depth': 200, 'max_features': 0.5, 'n_estimators': 10}\n",
            "0.947 (+/-0.031) for {'criterion': 'gini', 'max_depth': 200, 'max_features': 0.5, 'n_estimators': 20}\n",
            "0.957 (+/-0.023) for {'criterion': 'gini', 'max_depth': 200, 'max_features': 0.5, 'n_estimators': 100}\n",
            "0.941 (+/-0.030) for {'criterion': 'gini', 'max_depth': 200, 'max_features': 1.0, 'n_estimators': 10}\n",
            "0.959 (+/-0.022) for {'criterion': 'gini', 'max_depth': 200, 'max_features': 1.0, 'n_estimators': 20}\n",
            "0.954 (+/-0.021) for {'criterion': 'gini', 'max_depth': 200, 'max_features': 1.0, 'n_estimators': 100}\n",
            "0.945 (+/-0.050) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 0.5, 'n_estimators': 10}\n",
            "0.948 (+/-0.044) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 0.5, 'n_estimators': 20}\n",
            "0.951 (+/-0.043) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 0.5, 'n_estimators': 100}\n",
            "0.955 (+/-0.022) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 1.0, 'n_estimators': 10}\n",
            "0.960 (+/-0.023) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 1.0, 'n_estimators': 20}\n",
            "0.957 (+/-0.019) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 1.0, 'n_estimators': 100}\n",
            "0.936 (+/-0.048) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 0.5, 'n_estimators': 10}\n",
            "0.941 (+/-0.043) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 0.5, 'n_estimators': 20}\n",
            "0.950 (+/-0.023) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 0.5, 'n_estimators': 100}\n",
            "0.942 (+/-0.042) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 1.0, 'n_estimators': 10}\n",
            "0.942 (+/-0.050) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 1.0, 'n_estimators': 20}\n",
            "0.953 (+/-0.029) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 1.0, 'n_estimators': 100}\n",
            "0.959 (+/-0.022) for {'criterion': 'entropy', 'max_depth': 200, 'max_features': 0.5, 'n_estimators': 10}\n",
            "0.945 (+/-0.017) for {'criterion': 'entropy', 'max_depth': 200, 'max_features': 0.5, 'n_estimators': 20}\n",
            "0.956 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 200, 'max_features': 0.5, 'n_estimators': 100}\n",
            "0.955 (+/-0.018) for {'criterion': 'entropy', 'max_depth': 200, 'max_features': 1.0, 'n_estimators': 10}\n",
            "0.954 (+/-0.038) for {'criterion': 'entropy', 'max_depth': 200, 'max_features': 1.0, 'n_estimators': 20}\n",
            "0.960 (+/-0.011) for {'criterion': 'entropy', 'max_depth': 200, 'max_features': 1.0, 'n_estimators': 100}\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        47\n",
            "           1       0.99      0.99      0.99        67\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.98      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[46  1]\n",
            " [ 1 66]]\n",
            "Precision Score: \n",
            "\n",
            "0.9850746268656716\n",
            "################   AdaBoostClassifier   ################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "45 fits failed out of a total of 90.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "45 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'algorithm' parameter of AdaBoostClassifier must be a str among {'SAMME'}. Got 'SAMME.R' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96473786 0.97381177 0.97205138 0.96487589 0.9697361  0.9768713\n",
            " 0.96524355 0.96292806 0.96610956        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "{'algorithm': 'SAMME', 'learning_rate': 0.8, 'n_estimators': 200, 'random_state': None}\n",
            "Grid scores on development set:\n",
            "0.965 (+/-0.020) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': None}\n",
            "0.974 (+/-0.028) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': None}\n",
            "0.972 (+/-0.028) for {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 200, 'random_state': None}\n",
            "0.965 (+/-0.026) for {'algorithm': 'SAMME', 'learning_rate': 0.8, 'n_estimators': 50, 'random_state': None}\n",
            "0.970 (+/-0.024) for {'algorithm': 'SAMME', 'learning_rate': 0.8, 'n_estimators': 100, 'random_state': None}\n",
            "0.977 (+/-0.032) for {'algorithm': 'SAMME', 'learning_rate': 0.8, 'n_estimators': 200, 'random_state': None}\n",
            "0.965 (+/-0.018) for {'algorithm': 'SAMME', 'learning_rate': 0.5, 'n_estimators': 50, 'random_state': None}\n",
            "0.963 (+/-0.013) for {'algorithm': 'SAMME', 'learning_rate': 0.5, 'n_estimators': 100, 'random_state': None}\n",
            "0.966 (+/-0.021) for {'algorithm': 'SAMME', 'learning_rate': 0.5, 'n_estimators': 200, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'n_estimators': 200, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 0.8, 'n_estimators': 50, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 0.8, 'n_estimators': 100, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 0.8, 'n_estimators': 200, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 0.5, 'n_estimators': 50, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 0.5, 'n_estimators': 100, 'random_state': None}\n",
            "nan (+/-nan) for {'algorithm': 'SAMME.R', 'learning_rate': 0.5, 'n_estimators': 200, 'random_state': None}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "45 fits failed out of a total of 90.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "45 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'algorithm' parameter of AdaBoostClassifier must be a str among {'SAMME'}. Got 'SAMME.R' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96473786 0.97381177 0.97205138 0.96487589 0.9697361  0.9768713\n",
            " 0.96524355 0.96292806 0.96610956        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        47\n",
            "           1       0.99      0.99      0.99        67\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.98      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[46  1]\n",
            " [ 1 66]]\n",
            "Precision Score: \n",
            "\n",
            "0.9850746268656716\n",
            "################   GradientBoostingClassifier   ################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "90 fits failed out of a total of 180.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.96270036 0.96756821 0.96917435 0.96571826 0.96117293 0.96757755\n",
            " 0.95186054 0.95479098 0.95124644 0.95179693 0.95255376 0.95918992\n",
            " 0.95294796 0.95645588 0.95980648 0.95415056 0.95645588 0.95479098]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "{'loss': 'exponential', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 500}\n",
            "Grid scores on development set:\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 200}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 500}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 500}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 200}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 500}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 500}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 50, 'max_features': 'log2', 'n_estimators': 100}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 50, 'max_features': 'log2', 'n_estimators': 200}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 50, 'max_features': 'log2', 'n_estimators': 500}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 50, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 50, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "nan (+/-nan) for {'loss': 'deviance', 'max_depth': 50, 'max_features': 'sqrt', 'n_estimators': 500}\n",
            "0.963 (+/-0.041) for {'loss': 'exponential', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}\n",
            "0.968 (+/-0.041) for {'loss': 'exponential', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 200}\n",
            "0.969 (+/-0.037) for {'loss': 'exponential', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 500}\n",
            "0.966 (+/-0.031) for {'loss': 'exponential', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "0.961 (+/-0.039) for {'loss': 'exponential', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "0.968 (+/-0.036) for {'loss': 'exponential', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 500}\n",
            "0.952 (+/-0.021) for {'loss': 'exponential', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n",
            "0.955 (+/-0.032) for {'loss': 'exponential', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 200}\n",
            "0.951 (+/-0.030) for {'loss': 'exponential', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 500}\n",
            "0.952 (+/-0.030) for {'loss': 'exponential', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "0.953 (+/-0.029) for {'loss': 'exponential', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "0.959 (+/-0.035) for {'loss': 'exponential', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 500}\n",
            "0.953 (+/-0.039) for {'loss': 'exponential', 'max_depth': 50, 'max_features': 'log2', 'n_estimators': 100}\n",
            "0.956 (+/-0.032) for {'loss': 'exponential', 'max_depth': 50, 'max_features': 'log2', 'n_estimators': 200}\n",
            "0.960 (+/-0.020) for {'loss': 'exponential', 'max_depth': 50, 'max_features': 'log2', 'n_estimators': 500}\n",
            "0.954 (+/-0.032) for {'loss': 'exponential', 'max_depth': 50, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "0.956 (+/-0.032) for {'loss': 'exponential', 'max_depth': 50, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "0.955 (+/-0.032) for {'loss': 'exponential', 'max_depth': 50, 'max_features': 'sqrt', 'n_estimators': 500}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "90 fits failed out of a total of 180.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.96315997 0.9641556  0.96722305 0.96412911 0.96750499 0.96428187\n",
            " 0.95788403 0.95017485 0.95980648 0.95514752 0.95645588 0.95645588\n",
            " 0.95814157 0.95217193 0.95179693 0.95394008 0.9530804  0.95645588]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97        47\n",
            "           1       0.97      0.99      0.98        67\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[45  2]\n",
            " [ 1 66]]\n",
            "Precision Score: \n",
            "\n",
            "0.9705882352941176\n",
            "################   XGBClassifier   ################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters set found on development set:\n",
            "{'booster': 'gblinear', 'learning_rate': 0.05, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "Grid scores on development set:\n",
            "0.957 (+/-0.032) for {'booster': 'gbtree', 'learning_rate': 0.1, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "0.956 (+/-0.038) for {'booster': 'gbtree', 'learning_rate': 0.05, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "0.967 (+/-0.024) for {'booster': 'gbtree', 'learning_rate': 0.2, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "0.967 (+/-0.036) for {'booster': 'gblinear', 'learning_rate': 0.1, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "0.972 (+/-0.032) for {'booster': 'gblinear', 'learning_rate': 0.05, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "0.965 (+/-0.049) for {'booster': 'gblinear', 'learning_rate': 0.2, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "0.957 (+/-0.032) for {'booster': 'dart', 'learning_rate': 0.1, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "0.956 (+/-0.038) for {'booster': 'dart', 'learning_rate': 0.05, 'max_delta_step': 0, 'min_child_weight': 1}\n",
            "0.967 (+/-0.024) for {'booster': 'dart', 'learning_rate': 0.2, 'max_delta_step': 0, 'min_child_weight': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        47\n",
            "           1       0.97      0.97      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Detailed confusion matrix:\n",
            "[[45  2]\n",
            " [ 2 65]]\n",
            "Precision Score: \n",
            "\n",
            "0.9701492537313433\n",
            "\n",
            "Grid search completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:56:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"max_delta_step\", \"min_child_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# This code performs a grid search to find the best hyperparameters for a variety of machine learning algorithms on the breast cancer dataset.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets, model_selection, metrics, preprocessing\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "\n",
        "# Preprocess the dataset\n",
        "X = cancer['data']\n",
        "y = cancer['target']\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define the parameters to search over for each algorithm\n",
        "tuned_parameters = [[{'kernel': ['rbf', 'linear'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
        "                    [{'max_depth': [10, 100, 1000, 10000], 'min_samples_split': [2, 10, 100], 'min_samples_leaf': [1, 5, 10], 'max_features': [\"sqrt\", \"log2\"]}],\n",
        "                    [{'activation': ['logistic', 'tanh', 'relu'], 'hidden_layer_sizes': [(5,), (10,)], 'max_iter': [200, 1000], 'alpha': [0.0001, 0.0005]}],\n",
        "                    [{}],  # GaussianNB\n",
        "                    [{'penalty': ['l1', 'l2'], 'tol': [1e-4, 1e-5], 'max_iter': [10, 100, 1000], 'fit_intercept': [True, False]}],\n",
        "                    [{'n_neighbors': [5, 10, 20], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2, 3]}],\n",
        "                    [{'n_estimators': [10, 20, 100], 'max_samples': [0.5, 1.0], 'max_features': [0.5, 1.0], 'random_state': [None]}],\n",
        "                    [{'n_estimators': [10, 20, 100], 'max_features': [0.5, 1.0], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 100, 200]}],\n",
        "                    [{'n_estimators': [50, 100, 200], 'random_state': [None], 'learning_rate': [1., 0.8, 0.5], 'algorithm': ['SAMME', 'SAMME.R']}],\n",
        "                    [{'loss': ['deviance', 'exponential'], 'n_estimators': [100, 200, 500], 'max_features': ['log2', 'sqrt'], 'max_depth': [3, 10, 50]}],\n",
        "                    [{'booster': ['gbtree', 'gblinear', 'dart'], 'learning_rate': [0.1, 0.05, 0.2], 'min_child_weight': [1], 'max_delta_step': [0]}]]\n",
        "\n",
        "# Define the list of algorithms to tune\n",
        "algorithms = [SVC(), DecisionTreeClassifier(), MLPClassifier(), GaussianNB(), LogisticRegression(), KNeighborsClassifier(), BaggingClassifier(), RandomForestClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
        "\n",
        "# Define the list of algorithm names\n",
        "algorithm_names = [\"SVC\",\n",
        "                   \"DecisionTreeClassifier\",\n",
        "                   \"MLPClassifier\",\n",
        "                   \"GaussianNB\",\n",
        "                   \"LogisticRegression\",\n",
        "                   \"KNeighborsClassifier\",\n",
        "                   \"BaggingClassifier\",\n",
        "                   \"RandomForestClassifier\",\n",
        "                   \"AdaBoostClassifier\",\n",
        "                   \"GradientBoostingClassifier\",\n",
        "                   \"XGBClassifier\"]\n",
        "\n",
        "# Perform grid search for each algorithm\n",
        "for i in range(0, 11):\n",
        "    print(\"################   %s   ################\" % algorithm_names[i])\n",
        "\n",
        "    # Define the scoring metric to use\n",
        "    score = 'precision_macro'\n",
        "\n",
        "    # Create a GridSearchCV object\n",
        "    clf = model_selection.GridSearchCV(estimator=algorithms[i], param_grid=tuned_parameters[i], cv=5, scoring=score)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Print the best parameters found\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print(clf.best_params_)\n",
        "\n",
        "    # Print the grid scores on the development set\n",
        "    print(\"Grid scores on development set:\")\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "\n",
        "    # Train the model on the full development set\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Print the classification report\n",
        "    print(\"Detailed classification report:\")\n",
        "    print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "    # Print the confusion matrix\n",
        "    print(\"Detailed confusion matrix:\")\n",
        "    print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Print the precision score\n",
        "    print(\"Precision Score: \\n\")\n",
        "    print(metrics.precision_score(y_test, y_pred))\n",
        "\n",
        "# Print the completed message\n",
        "print(\"\\nGrid search completed!\")\n"
      ]
    }
  ]
}